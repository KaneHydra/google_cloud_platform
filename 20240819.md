---
id: "20240819"
aliases: []
tags: []
---

# 20240819

## 建立專案 與 資料集

1. 建立專案 `ai-project-座號-0819`

2. 左上三條線 導覽選單 => API和服務 => 程式庫, 搜尋並啟用以下服務：

    - BigQuery API
    - Vertex AI API
    - Cloud Storage

3. 開啟 Big Query Studio,  
   點左邊`ai-project-座號-0819`右邊的三個點,  
   建立資料庫：

    - 名稱`ai_dataset_座號`,
    - 地區 多地區 US

4. 左邊Explorer右邊的的新增 => 右上的 連接至外部資料來源 =>

    - Vertex AI 遠端模型、遠端函式和 BigLake Cloud 資源
    - 名稱 `ai_content`,
    - 地區 要跟上面的相同

5. 建完之後點左邊的外部連線 => `us_ai_content` => 複製右邊的服務帳戶ID

6. 左上三條線 導覽選單 => IAM 管理 => 身份和存取權管理 => 中間的 授予存取權 =>
    - 新增主體 貼上剛才複製的服務帳號ID
    - 指派角色：
        - BigQuery管理員
        - Storage管理員
        - VertexAI管理員

## 導入時間序列資料集

[查看老師的講義](https://hackmd.io/@4HupY3slSPWy7VByk-0aXA/r1TUvEvuC#0819課程資料)

[針對Google Analytics範例進行時間序列分析](https://hackmd.io/@4HupY3slSPWy7VByk-0aXA/BJGC-2UOR)

左上角三條線 導覽選單 => Big Query Studio => 中間輸入框上方正方形的加號 就是 新增查詢

1. 可視化時間序列

新增查詢, 並儲存為 `查詢時間序列`

```sql
SELECT
  PARSE_TIMESTAMP("%Y%m%d", date) AS parsed_date,
  SUM(totals.visits) AS total_visits
FROM
  `bigquery-public-data.google_analytics_sample.ga_sessions_*`
GROUP BY date
```

2. 創建時間序列模型

新增另一個查詢

資料集ID 為 `ai-project-座號-0819.ai_dataset_座號`

```sql
CREATE OR REPLACE MODEL `資料集ID.ga_arima_model`
OPTIONS (
    model_type = 'ARIMA_PLUS',
    -- 對應下方選擇的欄位
    time_series_timestamp_col = 'parsed_date',
    time_series_data_col = 'total_visits',
    --其他參數
    auto_arima = TRUE,
    data_frequency = 'AUTO_FREQUENCY',
    decompose_time_series = TRUE
) AS
-- 查詢時間序列
SELECT
  PARSE_TIMESTAMP("%Y%m%d", date) AS parsed_date,
  SUM(totals.visits) AS total_visits
FROM
  `bigquery-public-data.google_analytics_sample.ga_sessions_*`
GROUP BY date
```

3. 檢查所有模型評估指標

點左邊的 `ai_dataset_座號` => 模型 => `ga_arima_model` => 中間的 評估,  
可以看到訓練的 評估結果

使用查詢 查看 評估結果

```sql
SELECT * FROM ML.ARIMA_EVALUATE(MODEL `資料集ID.ga_arima_model`)
```

4. 檢查模型係數

```sql
SELECT * FROM ML.ARIMA_COEFFICIENTS(MODEL `資料集ID.ga_arima_model`)
```

5. 時間序列預測

```sql
SELECT * FROM
    ML.FORECAST(
        MODEL `資料集ID.ga_arima_model`,
        -- 預測 30 天, 水平為 0.8
        STRUCT(30 AS horizon, 0.8 AS confidence_level)
    )
```

查詢結果出來後, 右邊的 探索資料 => 透過 LookerStudio 探索,  
不過這裡是預設圖表,  
我們等等要改成比較適合表答時間序列化的圖表

6. 連接原始資料跟預設資料

## 使用 python SDK

1. 建立 服務帳號

左上角三條線 導覽選單 => IAM 與管理 => 身份與存取權管理

左邊找服務帳戶 => 建立服務帳號

名稱 `ai-test-25`
ID `ai-test-25`
這裡可以服務帳號的電子郵件地址產生規則

授予權限

-   BigQuery管理員
-   Storage管理員
-   VertexAI管理員

## 串 LINE dev 官方帳號

https://hackmd.io/@4HupY3slSPWy7VByk-0aXA/BkXjcsy50

裝 ngrok
把本地 5000 服務跑起來

```sh
ngrok http http://localhost:5000
```

顯示結果如下

```
ngrok                                                                            (Ctrl+C to quit)
New guides https://ngrok.com/docs/guides/site-to-site-apis/
Session Status                online
Account                       kanehydra@gmail.com (Plan: Free)
Version                       3.14.0
Region                        Japan (jp)
Latency                       68ms
Web Interface                 http://127.0.0.1:4040
Forwarding                    https://f808-61-216-172-121.ngrok-free.app -> http://localhost:5000
Connections                   ttl     opn     rt1     rt5     p50     p90
                              0       0       0.00    0.00    0.00    0.00
```

然後複製他的對外網址,後面加上 `/callback`

變成這樣 `https://f808-61-216-172-121.ngrok-free.app/callback`

貼到LINE DEV 上面的 webhook的地方

之後裝 flask

```
pip install flask line-bot-sdk google-generativeai Pillow
```

Gemini 1.5以上的版本才能使用圖片

MacOS 的 5000 port 是預設被系統佔用的，要注意
